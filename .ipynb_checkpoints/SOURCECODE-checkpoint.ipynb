{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc6cace-1759-4aac-b412-2b9e083870e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 30250\n",
      "Number of validation images: 6300\n",
      "Number of testing images: 6300\n",
      "Classes: ['nowildfire', 'wildfire']\n",
      "Sample image shape (C,H,W): torch.Size([3, 224, 224])\n",
      "Sample image label: nowildfire\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Wildfire Prediction - Week 1 Project\n",
    "# ===============================\n",
    "\n",
    "# 1. Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# 2. Load the dataset\n",
    "# Define transforms (resize and normalize)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Adjust dataset path as per your folder structure\n",
    "train_dataset = datasets.ImageFolder(root=\"train\", transform=transform)\n",
    "valid_dataset = datasets.ImageFolder(root=\"valid\", transform=transform)\n",
    "test_dataset  = datasets.ImageFolder(root=\"test\",  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Equivalent of .info() -> Dataset summary\n",
    "print(\"Number of training images:\", len(train_dataset))\n",
    "print(\"Number of validation images:\", len(valid_dataset))\n",
    "print(\"Number of testing images:\", len(test_dataset))\n",
    "print(\"Classes:\", train_dataset.classes)\n",
    "\n",
    "# Equivalent of .describe() -> Check one sample\n",
    "img, label = train_dataset[0]\n",
    "print(\"Sample image shape (C,H,W):\", img.shape)\n",
    "print(\"Sample image label:\", train_dataset.classes[label])\n",
    "\n",
    "# Equivalent of .isnull().sum() -> Check for missing/broken files\n",
    "missing_files = [path for path, _ in train_dataset.samples if not os.path.exists(path)]\n",
    "print(\"Missing or corrupted files in training set:\", len(missing_files))\n",
    "\n",
    "# 3. Explore the dataset\n",
    "\n",
    "# ðŸ”¹ Class distribution for training set\n",
    "labels = [label for _, label in train_dataset.samples]\n",
    "sns.countplot(x=labels)\n",
    "plt.title(\"Class Distribution in Training Dataset\")\n",
    "plt.xlabel(\"Class ID\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917fb966-1255-4997-af4b-8cdc9980da0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
